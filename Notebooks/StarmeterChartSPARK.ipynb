{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (9.0.0)\n",
      "Requirement already satisfied: pandas in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: ipython in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (8.24.0)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: decorator in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from stack-data->ipython) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from stack-data->ipython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from stack-data->ipython) (0.2.2)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python pandas matplotlib ipython python-dotenv "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install dash dash-bootstrap-components"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install sqlalchemy mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "import dash\n",
    "import plotly.graph_objs as go\n",
    "from dash import dcc, html, Input, Output, State, callback, ctx\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "from sqlalchemy import create_engine\n",
    "import traceback  # To print full error stack trace"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Function to create a raw MySQL connection\n",
    "def create_connection():\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='zipcode123',\n",
    "        database='starmerter_sim' \n",
    "\n",
    "    )\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# def create_connection():\n",
    "# Replace these variables with your actual database credentials\n",
    "    # username = 'root'\n",
    "    # password = 'zipcode123'\n",
    "    # host = 'localhost'\n",
    "    # database = 'starmerter_sim'\n",
    "\n",
    "    # # Use SQLAlchemy's create_engine with MySQL connector\n",
    "    # connection_string = f'mysql+mysqlconnector://{username}:{password}@{host}/{database}'\n",
    "    # engine = create_engine(connection_string)\n",
    "    # return engine\n",
    "\n",
    "# Replace with actual credentials\n",
    "connection_string = \"mysql+mysqlconnector://root:zipcode123@localhost/starmeter_sim\"\n",
    "\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    connection = engine.connect()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "    connection.close()  # Close the connection after testing\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to the database.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "username = 'root'\n",
    "password = 'zipcode123'\n",
    "host = 'localhost'\n",
    "database = 'starmerter_sim'\n",
    "connection_string = f'mysql+mysqlconnector://{username}:{password}@{host}/{database}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Event Sim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import mysql.connector\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def create_connection():\n",
    "    connection = mysql.connector.connect(\n",
    "    host = os.getenv('DB_HOST'),\n",
    "    user = os.getenv('DB_USER'),\n",
    "    password = os.getenv('DB_PASSWORD'),\n",
    "    database = os.getenv('DB_NAME')\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return connection\n",
    "\n",
    "conn = create_connection()\n",
    "\n",
    "event_probabilities={\n",
    "        'E1' :0.23,\n",
    "        'E2':0.07,\n",
    "        'E3':0.05,\n",
    "        'E4':0.05,\n",
    "        'E5':0.06,\n",
    "        'E6':0.03,\n",
    "        'E7':0.02,\n",
    "        'E8':0.02,\n",
    "        'E9':0.03,\n",
    "        'E10':0.03,\n",
    "        'E11':0.03,\n",
    "        'E12':0.03,\n",
    "        'E13':0.04,\n",
    "        'E14':0.01,\n",
    "        'E15':0.03,\n",
    "        'E16':0.02,\n",
    "        'E17':0.04,\n",
    "        'E18':0.01,\n",
    "        'E19':0.01,\n",
    "        'E20':0.02,\n",
    "        'E21':0.02,\n",
    "        'E22':0.01,\n",
    "        'E23':0.01,\n",
    "        'E24':0.01,\n",
    "        'E25':0.01,\n",
    "        'E26':0.01,\n",
    "        'E27':0.02,\n",
    "        'E28':0.01,\n",
    "        'E29':0.02,\n",
    "        'SC1':0.001,\n",
    "        'SC2':0.001,\n",
    "        'SC3':0.0045,\n",
    "        'SC4':0.005,\n",
    "        'SC5':0.001,\n",
    "        'SD1':0.0005,\n",
    "        'SD2':0.005,\n",
    "        'SD3':0.0025,\n",
    "        'SD4':0.001,\n",
    "        'SD5':0.0035,\n",
    "        'T1':0.0005,\n",
    "        'T2':0.005,\n",
    "        'T3':0.002,\n",
    "        'T4':0.005,\n",
    "        'L1':0.0005,\n",
    "        'L2':0.001,\n",
    "        'L3':0.0005,\n",
    "        'L4':0.0015,\n",
    "        'L5':0.0015,\n",
    "        'L6':0.0075\n",
    "}\n",
    "\n",
    "event_descriptions = {\n",
    "    'E1': 'Nothing new',\n",
    "    'E2': 'Public appearance',\n",
    "    'E3': 'Got Award',\n",
    "    'E4': 'Philanthropy/donation',\n",
    "    'E5': 'New post on social media (positive)',\n",
    "    'E6': 'New post on social media (negative)',\n",
    "    'E7': 'Public argument/feud',\n",
    "    'E8': 'Legal issue',\n",
    "    'E9': 'Poor performance',\n",
    "    'E10': 'Controversial statement',\n",
    "    'E11': 'Attends high profile event',\n",
    "    'E12': 'Cameo appearance',\n",
    "    'E13': 'New project or franchise',\n",
    "    'E14': 'Gets married/has child',\n",
    "    'E15': 'New social media platform',\n",
    "    'E16': 'Major news story',\n",
    "    'E17': 'Celebrity collaboration',\n",
    "    'E18': 'Health decline',\n",
    "    'E19': 'Podcast appearance',\n",
    "    'E20': 'Health fitness',\n",
    "    'E21': 'Talk show appearance',\n",
    "    'E22': 'Feature film',\n",
    "    'E23': 'Scandalous clothing',\n",
    "    'E24': 'Bizarre fashion choice',\n",
    "    'E25': 'Mysterious post/teaser',\n",
    "    'E26': 'Book/memoir',\n",
    "    'E27': 'Candid photograph / normal day',\n",
    "    'E28': 'Request of fans',\n",
    "    'E29': 'Political alignment',\n",
    "    'SC1': 'Releases new album/tour',\n",
    "    'SC2': 'Hosts SNL',\n",
    "    'SC3': 'Relationship drama',\n",
    "    'SC4': 'Hit Song',\n",
    "    'SC5': 'Launching a fashion line',\n",
    "    'SD1': 'Carry torch at Olympics',\n",
    "    'SD2': 'Music Performance',\n",
    "    'SD3': 'Offensive comments',\n",
    "    'SD4': 'Newfound public friendship with Bill Gates',\n",
    "    'SD5': 'Featured in a new song',\n",
    "    'T1': 'Developed new suit',\n",
    "    'T2': 'Saved the world',\n",
    "    'T3': 'Become a villain',\n",
    "    'T4': 'Public appearance with iron man suit',\n",
    "    'L1': 'Losses in NBA playoffs',\n",
    "    'L2': 'Son gets drafted onto same team',\n",
    "    'L3': 'Wins Olympic Gold Medal',\n",
    "    'L4': 'Releases new shoe/product',\n",
    "    'L5': 'Gets Injured',\n",
    "    'L6': 'Sits out for rest'\n",
    "}\n",
    "\n",
    "#make sure the sum of the probability it's 1\n",
    "print(sum(event_probabilities.values()))\n",
    "\n",
    "category_1_events = {'E2', 'E3', 'E4', 'E5', 'E11', 'E12', 'E13', 'E14','E15', 'E16', 'E17', 'E18', 'E19', 'E20', 'E21', 'E22', 'E25', 'E26' }\n",
    "category_2_events = {'E1', 'E10', 'E16', 'E24', 'E27', 'E28'}\n",
    "category_3_events = {'E6', 'E7', 'E8', 'E9', 'E23', 'E29'}\n",
    "category_4_events = {'SC1', 'SC2', 'SC3', 'SC4', 'SC5', 'SD1', 'SD2', 'SD3', 'SD4', 'SD5', 'T1', 'T2', 'T3', 'T4', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6'}\n",
    "\n",
    "celebrities = ['Sabrina Carpenter', 'Snoop Dogg', 'Tony Stark', 'LeBron James']\n",
    "\n",
    "def choose_event():\n",
    "    events=list(event_probabilities.keys())\n",
    "    probabilities = list(event_probabilities.values())\n",
    "    event = random.choices(events,probabilities)[0]\n",
    "    return event\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reset_probability_to_default(connection,user_id):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    select_query = \"select E1,E2,E3,E4,E5,E6,E7,E8,E9,E10,E11,E12,E13,E14,E15,E16,E17,E18,E19,E20,E21,E22,E23,E24,E25,E26,E27,E28,E29,SC1,SC2,SC3,SC4,SC5,SD1,SD2,SD3,SD4,SD5,T1,T2,T3,T4,L1,L2,L3,L4,L5,L6 from user_default_settings where user_id = %s\"\n",
    "    cursor.execute(select_query, (user_id,))\n",
    "    default_probs = cursor.fetchone()\n",
    "\n",
    "    #uptade the user_dynamic_preferences table\n",
    "    update_query = \"\"\"\n",
    "    update user_dynamic_preferences set\n",
    "    E1 = %s, E2 = %s, E3 = %s, E4 = %s, E5 = %s, E6 = %s, E7 = %s, E8 = %s, E9 = %s, E10 = %s, E11 = %s, E12 = %s, E13 = %s, E14 = %s, E15 = %s, E16 = %s, E17 = %s, E18 = %s, E19 = %s, E20 = %s, E21 = %s, E22 = %s, E23 = %s, E24 = %s, E25 = %s, E26 = %s, E27 = %s, E28 = %s, E29 = %s, SC1 = %s, SC2 = %s, SC3 = %s, SC4 = %s, SC5 = %s, SD1 = %s, SD2 = %s, SD3 = %s, SD4 = %s, SD5 = %s, T1 = %s, T2 = %s, T3 = %s, T4 = %s, L1 = %s, L2 = %s, L3 = %s, L4 = %s, L5 = %s, L6 = %s\n",
    "    where user_id = %s\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query, (*default_probs, user_id))\n",
    "    connection.commit()\n",
    "\n",
    "    #print(f\"User {user_id} probabilities reset to default\")\n",
    "\n",
    "\n",
    "def situation_category_1_event(connection, event, associated_celebrity):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    select_query = f\"select user_id, current_favorite, {event} from user_dynamic_preferences\"\n",
    "    cursor.execute(select_query)\n",
    "    users = cursor.fetchall()\n",
    "\n",
    "    for user in users:\n",
    "        user_id = user[0]\n",
    "        current_favorite = user[1]\n",
    "        event_prob = user[2]\n",
    "\n",
    "        #should change or not, Dice rolling!!!\n",
    "        if random.random() < event_prob:\n",
    "            new_favorite = random.choice(celebrities)\n",
    "            update_query = \"update user_dynamic_preferences set current_favorite = %s where user_id = %s\"\n",
    "            cursor.execute(update_query, (new_favorite, user_id))\n",
    "            reset_probability_to_default(connection, user_id)\n",
    "            #print(f\"User {user_id} changed favorite to {associated_celebrity} due to event {event_descriptions[event]}\")\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "\n",
    "def situation_category_2_event(connection, event, associated_celebrity):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    select_query = f\"SELECT user_id, current_favorite, {event} FROM user_dynamic_preferences WHERE current_favorite = %s\"\n",
    "    cursor.execute(select_query, (associated_celebrity,))\n",
    "    users = cursor.fetchall()\n",
    "\n",
    "    for user in users:\n",
    "        user_id = user[0]\n",
    "        event_prob = user[2]\n",
    "\n",
    "        #should change or not, Dice rolling!!!\n",
    "        if random.random() < event_prob:\n",
    "            new_favorite = random.choice([celeb for celeb in celebrities if celeb != associated_celebrity])\n",
    "            update_query = \"UPDATE user_dynamic_preferences SET current_favorite = %s WHERE user_id = %s\"\n",
    "            cursor.execute(update_query, (new_favorite, user_id))\n",
    "            reset_probability_to_default(connection, user_id)\n",
    "            #print(f\"User {user_id} changed favorite from {associated_celebrity} to {new_favorite} due to event {event_descriptions[event]}\")\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "def situation_category_3_event(connection, event, associated_celebrity):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    select_query = f\"SELECT user_id, current_favorite, {event} FROM user_dynamic_preferences WHERE current_favorite = %s\"\n",
    "    cursor.execute(select_query, (associated_celebrity,))\n",
    "    users = cursor.fetchall()\n",
    "\n",
    "    for user in users:\n",
    "        user_id = user[0]\n",
    "        event_prob = user[2]\n",
    "\n",
    "        #should change or not, Dice rolling!!!\n",
    "        if random.random() < event_prob:\n",
    "            new_favorite = random.choice([celeb for celeb in celebrities if celeb != associated_celebrity])\n",
    "            update_query = \"UPDATE user_dynamic_preferences SET current_favorite = %s WHERE user_id = %s\"\n",
    "            cursor.execute(update_query, (new_favorite, user_id))\n",
    "            reset_probability_to_default(connection, user_id)\n",
    "            #print(f\"User {user_id} changed favorite from {associated_celebrity} to {new_favorite} due to event {event}\")\n",
    "        else:\n",
    "            new_prob = min(event_prob + 0.15, 1.0)\n",
    "            update_prob_query = f\"UPDATE user_dynamic_preferences SET {event} = %s WHERE user_id = %s\"\n",
    "            cursor.execute(update_prob_query, (new_prob, user_id))\n",
    "            #print(f\"User {user_id}'s probability for event {event_descriptions[event]} increased to {new_prob}\")\n",
    "\n",
    "    connection.commit()\n",
    "    \n",
    "def stuation_category_4_event(connection, event, associated_celebrity):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    select_query = f\"SELECT user_id, current_favorite, {event} FROM user_dynamic_preferences WHERE current_favorite = %s\"\n",
    "    cursor.execute(select_query, (associated_celebrity,))\n",
    "    users = cursor.fetchall()\n",
    "\n",
    "    for user in users:\n",
    "        user_id = user[0]\n",
    "        event_prob = user[2]\n",
    "\n",
    "        #should change or not, Dice rolling!!!\n",
    "        if random.random() < event_prob:\n",
    "            new_favorite = random.choice([celeb for celeb in celebrities if celeb!= associated_celebrity])\n",
    "            update_query = \"UPDATE user_dynamic_preferences SET current_favorite = %s WHERE user_id = %s\"\n",
    "            cursor.execute(update_query, (new_favorite, user_id))\n",
    "            reset_probability_to_default(connection, user_id)\n",
    "            #print(f\"User {user_id} changed favorite from {associated_celebrity} to {new_favorite} due to event {event}\")\n",
    "\n",
    "\n",
    "def run_event_sum(connection, num_days = (6*30)):\n",
    "    for day in range(num_days):\n",
    "        print(f\"Simulating day {day+1}...\")\n",
    "\n",
    "        event = choose_event()\n",
    "        event_description = event_descriptions.get(event, \"Unknown event\")\n",
    "        associated_celebrity = random.choice(celebrities)\n",
    "        # print(f\"Event {event} occurred ({event_description}), associated with {associated_celebrity}\")\n",
    "\n",
    "        if event in category_1_events:\n",
    "            situation_category_1_event(conn, event, associated_celebrity)\n",
    "        elif event in category_2_events:\n",
    "            situation_category_2_event(conn, event, associated_celebrity)\n",
    "        elif event in category_3_events:\n",
    "            situation_category_3_event(conn, event, associated_celebrity)\n",
    "\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conn = create_connection()\n",
    "    if conn.is_connected():\n",
    "        print(\"Connected to the database\")\n",
    "        run_event_sum(conn, num_days=180)\n",
    "        conn.close()\n",
    "        print(\"Database connection closed\")\n",
    "    else:\n",
    "        print(\"Connection failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a connection\n",
    "def create_connection():\n",
    "    \"\"\"Create a connection to the MySQL database using SQLAlchemy.\"\"\"\n",
    "    try:\n",
    "        engine = create_engine(\n",
    "            \"mysql+mysqlconnector://timlinkous:zipcode1@localhost/starmeter\"\n",
    "        )\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 09:48:50 WARN Utils: Your hostname, Zipcoders-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.222 instead (on interface en0)\n",
      "24/09/07 09:48:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/timl/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/timl/.ivy2/jars\n",
      "mysql#mysql-connector-java added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-08c297f5-18a7-435d-a845-d6a6adbf7e5d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound mysql#mysql-connector-java;8.0.29 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.19.4 in central\n",
      ":: resolution report :: resolve 99ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.protobuf#protobuf-java;3.19.4 from central in [default]\n",
      "\tmysql#mysql-connector-java;8.0.29 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-08c297f5-18a7-435d-a845-d6a6adbf7e5d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/4ms)\n",
      "24/09/07 09:48:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/07 09:48:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/09/07 09:48:51 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15e99d490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 09:49:02 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "from dash import dcc, html, Output, Input, State\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySQL-Spark-Connection\") \\\n",
    "    .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.29\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Function to retrieve fan counts with error handling\n",
    "def get_fan_counts():\n",
    "    try:\n",
    "        # Fetch data using Spark\n",
    "        df = spark.read.format(\"jdbc\") \\\n",
    "            .option(\"url\", \"jdbc:mysql://localhost:3306/starmeter\") \\\n",
    "            .option(\"dbtable\", \"user_dynamic_preferences\") \\\n",
    "            .option(\"user\", \"timlinkous\") \\\n",
    "            .option(\"password\", \"zipcode1\") \\\n",
    "            .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "            .load()\n",
    "\n",
    "        # Perform the aggregation using Spark\n",
    "        fan_counts_df = df.groupBy(\"current_favorite\").count().withColumnRenamed(\"count\", \"fan_count\")\n",
    "\n",
    "        # Convert to Pandas DataFrame for Dash processing\n",
    "        fan_counts_pd = fan_counts_df.toPandas()\n",
    "\n",
    "        if fan_counts_pd.empty:\n",
    "            print(\"Warning: The retrieved DataFrame is empty.\")\n",
    "        return fan_counts_pd\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "        return pd.DataFrame(columns=['current_favorite', 'fan_count'])\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Initialize layout KPI cards interval component\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Real-Time Fan Count of Celebrities\"),\n",
    "    html.Div(id='kpi-cards', children=[\n",
    "        dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Total Fans\", className=\"card-title\"),\n",
    "                html.H5(id='total-fans', className=\"card-text\")\n",
    "            ])\n",
    "        ]),\n",
    "        dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Most Popular Celebrity\", className=\"card-title\"),\n",
    "                html.H5(id='most-popular-celebrity', className=\"card-text\")\n",
    "            ])\n",
    "        ]),\n",
    "    ]),\n",
    "    dcc.Graph(id='live-update-graph'),\n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=1000,  # update interval milliseconds\n",
    "        n_intervals=0,\n",
    "        disabled=True  # interval initially disabled\n",
    "    ),\n",
    "    html.Button('Start', id='start-stop-button', n_clicks=0, className=\"btn btn-primary\"),\n",
    "])\n",
    "\n",
    "# Initialize data storage\n",
    "fan_counts_data = {celebrity: [] for celebrity in ['Sabrina Carpenter', 'Snoop Dogg', 'Tony Stark', 'LeBron James']}\n",
    "time_data = []\n",
    "\n",
    "@app.callback(\n",
    "    [Output('live-update-graph', 'figure'),\n",
    "     Output('total-fans', 'children'),\n",
    "     Output('most-popular-celebrity', 'children')],\n",
    "    Input('interval-component', 'n_intervals')\n",
    ")\n",
    "def update_graph_and_kpis(n):\n",
    "    global time_data, fan_counts_data\n",
    "\n",
    "    try:\n",
    "        # Fetch latest fan counts using Spark\n",
    "        df = get_fan_counts()\n",
    "\n",
    "        # Initialize KPI variables\n",
    "        total_fans = 0\n",
    "        most_popular_celeb = None\n",
    "        max_fans = 0\n",
    "\n",
    "        if not df.empty:\n",
    "            # Append current timestamp\n",
    "            current_time = time.time()\n",
    "            time_data.append(current_time - time_data[0] if time_data else 0)\n",
    "\n",
    "            # Update fan counts data\n",
    "            for celebrity in fan_counts_data.keys():\n",
    "                fan_count = df[df['current_favorite'] == celebrity]['fan_count'].sum() if not df[df['current_favorite'] == celebrity].empty else 0\n",
    "                fan_counts_data[celebrity].append(fan_count)\n",
    "\n",
    "                # Update total fans and most popular celebrity\n",
    "                total_fans += fan_count\n",
    "                if fan_count > max_fans:\n",
    "                    max_fans = fan_count\n",
    "                    most_popular_celeb = celebrity\n",
    "\n",
    "            # Create traces for each celebrity\n",
    "            fig = go.Figure()\n",
    "            for celebrity, fan_counts in fan_counts_data.items():\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=time_data,\n",
    "                    y=fan_counts,\n",
    "                    mode='lines+markers',\n",
    "                    name=celebrity,\n",
    "                    marker=dict(size=5),\n",
    "                    text=[f'Followers {count}' for count in fan_counts],\n",
    "                    hoverinfo='text'\n",
    "                ))\n",
    "\n",
    "            # Ensure time_data has enough data points to set range\n",
    "            if len(time_data) > 1:\n",
    "                fig.update_layout(\n",
    "                    xaxis=dict(range=[max(time_data) - 100, max(time_data)]),\n",
    "                )\n",
    "\n",
    "            fig.update_layout(\n",
    "                xaxis_title='Time (seconds)',\n",
    "                yaxis_title='Number of Fans',\n",
    "                title='Real-Time Fan Count of Celebrities',\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            fig = go.Figure().update_layout(\n",
    "                title='No data available',\n",
    "                xaxis_title='Time (seconds)',\n",
    "                yaxis_title='Number of Fans'\n",
    "            )\n",
    "\n",
    "        return fig, f'{total_fans}', most_popular_celeb or 'No data'\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in updating graph and KPIs: {e}\")\n",
    "        return go.Figure().update_layout(title=\"Error updating graph\"), 'Error', 'Error'\n",
    "\n",
    "# Callback control start stop functionality\n",
    "@app.callback(\n",
    "    Output('interval-component', 'disabled'),\n",
    "    Output('start-stop-button', 'children'),\n",
    "    Input('start-stop-button', 'n_clicks'),\n",
    "    State('interval-component', 'disabled')\n",
    ")\n",
    "def toggle_interval(n_clicks, is_disabled):\n",
    "    # Toggle state interval (start stop updates)\n",
    "    if n_clicks % 2 == 0:\n",
    "        return True, 'Start'  # disabled, show 'Start' button text\n",
    "    else:\n",
    "        return False, 'Stop'  # enabled, show 'Stop' button text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve the fan count for each celebrity\n",
    "def get_fan_counts():\n",
    "    connection = create_connection()  # Assuming create_connection() is defined elsewhere\n",
    "    query = \"\"\"\n",
    "    SELECT current_favorite, COUNT(*) as fan_count \n",
    "    FROM user_dynamic_preferences \n",
    "    GROUP BY current_favorite;\n",
    "    \"\"\"\n",
    "    # Use the raw MySQL connection to fetch the data\n",
    "    df = pd.read_sql(query, con=connection)\n",
    "    connection.close()\n",
    "    return df\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Initialize layout with an empty figure and an interval component\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Real-Time Fan Count of Celebrities\"),\n",
    "    dcc.Graph(id='live-update-graph'),\n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=300,  # in milliseconds (0.3 seconds)\n",
    "        n_intervals=0\n",
    "    )\n",
    "])\n",
    "\n",
    "# Initialize data storage\n",
    "fan_counts_data = {celebrity: [] for celebrity in ['Sabrina Carpenter', 'Snoop Dogg', 'Tony Stark', 'LeBron James']}\n",
    "time_data = []\n",
    "\n",
    "# Callback to update the graph\n",
    "@app.callback(\n",
    "    Output('live-update-graph', 'figure'),\n",
    "    Input('interval-component', 'n_intervals')\n",
    ")\n",
    "def update_graph(n):\n",
    "    global time_data, fan_counts_data\n",
    "\n",
    "    # Fetch the latest fan counts\n",
    "    df = get_fan_counts()\n",
    "\n",
    "    # Append the current timestamp\n",
    "    current_time = time.time()\n",
    "    time_data.append(current_time - time_data[0] if time_data else 0)\n",
    "\n",
    "    # Update the fan counts data\n",
    "    for celebrity in fan_counts_data.keys():\n",
    "        fan_count = df[df['current_favorite'] == celebrity]['fan_count'].sum() if not df[df['current_favorite'] == celebrity].empty else 0\n",
    "        fan_counts_data[celebrity].append(fan_count)\n",
    "\n",
    "    # Create traces for each celebrity\n",
    "    fig = go.Figure()\n",
    "    for celebrity, fan_counts in fan_counts_data.items():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_data,\n",
    "            y=fan_counts,\n",
    "            mode='lines+markers',\n",
    "            name=celebrity\n",
    "        ))\n",
    "\n",
    "    # Set graph layout properties\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Time (seconds)',\n",
    "        yaxis_title='Number of Fans',\n",
    "        title='Real-Time Fan Count of Celebrities',\n",
    "        xaxis=dict(range=[max(time_data) - 100, max(time_data)]),\n",
    "        yaxis=dict(range=[0, 1000])\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import row_number, lag, sum, col, desc, when\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "def calculate_fan_count_changes(spark):\n",
    "    # Read the event_log table\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/starmeter\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .option(\"dbtable\", \"event_log\") \\\n",
    "        .option(\"user\", \"timlinkous\") \\\n",
    "        .option(\"password\", \"zipcode1\") \\\n",
    "        .load()\n",
    "\n",
    "    # Create a window spec sorted by event_date in descending order\n",
    "    window_spec = Window.partitionBy(\"celebrity\").orderBy(desc(\"event_date\"))\n",
    "\n",
    "    # Calculate the fan count changes\n",
    "    df_with_changes = df.withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
    "        .withColumn(\"previous_fan_count\", lag(\"current_fan_count\").over(window_spec)) \\\n",
    "        .withColumn(\"fan_count_change\", sum(col(\"fans_gained\") - col(\"fans_lost\")).over(window_spec))\n",
    "\n",
    "    return df_with_changes.select(\n",
    "        \"event_date\", \n",
    "        \"celebrity\", \n",
    "        \"event_description\", \n",
    "        \"current_fan_count\",\n",
    "        \"fan_count_change\"\n",
    "    ).orderBy(desc(\"event_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 11:18:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/09/07 11:18:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16b4e48c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import html, dcc\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import dash_table\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CelebrityFanCountDashboard\") \\\n",
    "    .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.29\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def fetch_and_calculate_changes():\n",
    "    # Fetch data from MySQL\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/starmeter\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .option(\"dbtable\", \"event_log\") \\\n",
    "        .option(\"user\", \"timlinkous\") \\\n",
    "        .option(\"password\", \"zipcode1\") \\\n",
    "        .load()\n",
    "\n",
    "    # Convert to Pandas DataFrame\n",
    "    pdf = df.select(\"event_date\", \"celebrity\", \"event_description\", \"current_fan_count\") \\\n",
    "        .orderBy(desc(\"event_date\")) \\\n",
    "        .limit(20).toPandas()\n",
    "\n",
    "    pdf = pdf.sort_values(['celebrity', 'event_date'])  # Sort in ascending order\n",
    "    pdf['fan_count_change'] = pdf.groupby('celebrity')['current_fan_count'].diff()\n",
    "    pdf['fan_count_change'] = pdf['fan_count_change'] * -1  # Invert the sign\n",
    "    pdf = pdf.sort_values('event_date', ascending=False)\n",
    "\n",
    "    # Keep only the 10 most recent events\n",
    "    pdf = pdf.head(10)\n",
    "\n",
    "    pdf['fan_count_change'] = pdf['fan_count_change'].fillna(0).astype(int)\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Celebrity Fan Count Real-Time Dashboard\"),\n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=5000,  # in milliseconds, update every 5 seconds\n",
    "        n_intervals=0\n",
    "    ),\n",
    "    dash_table.DataTable(\n",
    "        id='live-update-table',\n",
    "        columns=[\n",
    "            {\"name\": \"Event Date\", \"id\": \"event_date\"},\n",
    "            {\"name\": \"Celebrity\", \"id\": \"celebrity\"},\n",
    "            {\"name\": \"Event Description\", \"id\": \"event_description\"},\n",
    "            {\"name\": \"Current Fan Count\", \"id\": \"current_fan_count\"},\n",
    "            {\"name\": \"Fan Count Change\", \"id\": \"fan_count_change\"}\n",
    "        ],\n",
    "        style_table={'height': 'auto', 'overflowY': 'auto'},\n",
    "        style_cell={'textAlign': 'left'},\n",
    "        style_data_conditional=[\n",
    "            {\n",
    "                'if': {'column_id': 'fan_count_change', 'filter_query': '{fan_count_change} > 0'},\n",
    "                'color': 'green'\n",
    "            },\n",
    "            {\n",
    "                'if': {'column_id': 'fan_count_change', 'filter_query': '{fan_count_change} < 0'},\n",
    "                'color': 'red'\n",
    "            }\n",
    "        ],\n",
    "        sort_action='native',\n",
    "        sort_mode='multi'\n",
    "    )\n",
    "])\n",
    "\n",
    "# Callback to update the table\n",
    "@app.callback(\n",
    "    Output('live-update-table', 'data'),\n",
    "    Input('interval-component', 'n_intervals')\n",
    ")\n",
    "def update_table(n):\n",
    "    try:\n",
    "        df = fetch_and_calculate_changes()\n",
    "        return df.to_dict('records')\n",
    "    except Exception as e:\n",
    "        print(f\"Error in update_table: {str(e)}\")\n",
    "        return []  # Return empty list if there's an error\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
