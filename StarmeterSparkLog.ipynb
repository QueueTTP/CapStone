{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 18:41:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/07 18:41:09 WARN DependencyUtils: Local jar /Users/teddy/Documents/GitHub/projects/CapStone/jars/mysql-connector-java-8.4.0.jar does not exist, skipping.\n",
      "24/09/07 18:41:09 INFO SparkContext: Running Spark version 3.5.2\n",
      "24/09/07 18:41:09 INFO SparkContext: OS info Mac OS X, 14.6, aarch64\n",
      "24/09/07 18:41:09 INFO SparkContext: Java version 11.0.23\n",
      "24/09/07 18:41:09 INFO ResourceUtils: ==============================================================\n",
      "24/09/07 18:41:09 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/09/07 18:41:09 INFO ResourceUtils: ==============================================================\n",
      "24/09/07 18:41:09 INFO SparkContext: Submitted application: StarMeter\n",
      "24/09/07 18:41:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/09/07 18:41:09 INFO ResourceProfile: Limiting resource is cpu\n",
      "24/09/07 18:41:09 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/09/07 18:41:09 INFO SecurityManager: Changing view acls to: teddy\n",
      "24/09/07 18:41:09 INFO SecurityManager: Changing modify acls to: teddy\n",
      "24/09/07 18:41:09 INFO SecurityManager: Changing view acls groups to: \n",
      "24/09/07 18:41:09 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/09/07 18:41:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: teddy; groups with view permissions: EMPTY; users with modify permissions: teddy; groups with modify permissions: EMPTY\n",
      "24/09/07 18:41:09 INFO Utils: Successfully started service 'sparkDriver' on port 51048.\n",
      "24/09/07 18:41:10 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/09/07 18:41:10 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/09/07 18:41:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/09/07 18:41:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/09/07 18:41:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/09/07 18:41:10 INFO DiskBlockManager: Created local directory at /private/var/folders/20/24nsj1xx7y52k8m90_h_2r5h0000gp/T/blockmgr-14b8e946-9d15-4c61-8005-93870ce74da2\n",
      "24/09/07 18:41:10 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "24/09/07 18:41:10 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/09/07 18:41:10 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "24/09/07 18:41:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "24/09/07 18:41:10 ERROR SparkContext: Failed to add jars/mysql-connector-java-8.4.0.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /Users/teddy/Documents/GitHub/projects/CapStone/jars/mysql-connector-java-8.4.0.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/09/07 18:41:10 INFO Executor: Starting executor ID driver on host 192.168.10.107\n",
      "24/09/07 18:41:10 INFO Executor: OS info Mac OS X, 14.6, aarch64\n",
      "24/09/07 18:41:10 INFO Executor: Java version 11.0.23\n",
      "24/09/07 18:41:10 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "24/09/07 18:41:10 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2aee1d77 for default.\n",
      "24/09/07 18:41:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51049.\n",
      "24/09/07 18:41:10 INFO NettyBlockTransferService: Server created on 192.168.10.107:51049\n",
      "24/09/07 18:41:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/09/07 18:41:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.10.107, 51049, None)\n",
      "24/09/07 18:41:10 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.10.107:51049 with 434.4 MiB RAM, BlockManagerId(driver, 192.168.10.107, 51049, None)\n",
      "24/09/07 18:41:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.10.107, 51049, None)\n",
      "24/09/07 18:41:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.10.107, 51049, None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import dash\n",
    "from pyspark.sql.functions import desc\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "from dash import dcc, html, Output, Input, State\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from dash import dcc, html, Input, Output, State\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StarMeter\") \\\n",
    "    .config(\"spark.jars\", \"jars/mysql-connector-java-8.4.0.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Function to retrieve fan counts with error handling\n",
    "def get_fan_counts():\n",
    "    try:\n",
    "        # Fetch data using Spark\n",
    "        df = spark.read.format(\"jdbc\") \\\n",
    "            .option(\"url\", \"jdbc:mysql://127.0.0.1:3306/starmeter_sim\") \\\n",
    "            .option(\"dbtable\", \"user_dynamic_preferences\") \\\n",
    "            .option(\"user\", \"root\") \\\n",
    "            .option(\"password\", \"zipcode123\") \\\n",
    "            .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "            .load()\n",
    "\n",
    "        # Perform the aggregation using Spark\n",
    "        fan_counts_df = df.groupBy(\"current_favorite\").count().withColumnRenamed(\"count\", \"fan_count\")\n",
    "\n",
    "        # Convert to Pandas DataFrame for Dash processing\n",
    "        fan_counts_pd = fan_counts_df.toPandas()\n",
    "\n",
    "        if fan_counts_pd.empty:\n",
    "            print(\"Warning: The retrieved DataFrame is empty.\")\n",
    "        return fan_counts_pd\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "        return pd.DataFrame(columns=['current_favorite', 'fan_count'])\n",
    "\n",
    "\n",
    "\n",
    "def fetch_and_calculate_changes():\n",
    "    # Fetch data from MySQL\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/starmeter_sim\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .option(\"dbtable\", \"event_log\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"zipcode123\") \\\n",
    "        .load()\n",
    "\n",
    "    # Convert to Pandas DataFrame and select necessary columns\n",
    "    pdf = df.select(\"event_date\", \"celebrity\", \"event_description\", \"current_fan_count\") \\\n",
    "        .orderBy(F.desc(\"event_date\")) \\\n",
    "        .limit(10) \\\n",
    "        .toPandas()\n",
    "\n",
    "      # Calculate fan_count_change\n",
    "    pdf['fan_count_change'] = pdf['current_fan_count'].diff().fillna(0).astype(int)\n",
    "    \n",
    "    # Create the event log HTML using Dash components with specified font sizes\n",
    "    event_log_html = html.Div([\n",
    "        html.H4(\"Event Log\", style={'fontSize': '20px', 'marginBottom': '10px'}),  # Set font size for the header\n",
    "        html.Table([\n",
    "            html.Thead(html.Tr([\n",
    "                html.Th(\"Date\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Celebrity\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Event\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Change\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'})\n",
    "            ])),\n",
    "            html.Tbody([\n",
    "                html.Tr([\n",
    "                    html.Td(row['event_date'].strftime('%Y-%m-%d'), style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(row['celebrity'], style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(row['event_description'], style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(f\"{row['fan_count_change']:+d}\", style={'fontSize': '12px', 'padding': '5px', 'color': 'green' if row['fan_count_change'] > 0 else 'red' if row['fan_count_change'] < 0 else 'black'})\n",
    "                ]) for _, row in pdf.iterrows()\n",
    "            ])\n",
    "        ], style={'width': '100%', 'textAlign': 'left', 'borderCollapse': 'collapse'})\n",
    "    ])\n",
    "    \n",
    "    return event_log_html\n",
    "\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Define custom styles for KPI cards\n",
    "card_styles = [\n",
    "    {\"backgroundColor\": \"#0075A4\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#008FAD\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#00A697\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#1EB769\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"}\n",
    "]\n",
    "\n",
    "# Initialize layout with KPI cards next to each other and graph with legend on top\n",
    "app.layout = html.Div([\n",
    "     dbc.Row([\n",
    "        dbc.Col(html.Button('Start', id='start-stop-button', n_clicks=0, className=\"btn btn-primary\"), width=\"auto\"),\n",
    "        dbc.Col(html.H1(\"StarMeter\", style={\"fontSize\": \"24px\"}), width=True)\n",
    "    ], align='center', className=\"mb-4\"),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Total Fans (in thousands)\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='total-fans', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[0], className=\"mb-2\"), width=2),\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.Card
