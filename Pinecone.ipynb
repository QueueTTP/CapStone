{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x131353080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import dash\n",
    "from pyspark.sql.functions import desc\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "from dash import dcc, html, Output, Input, State\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from dash import dcc, html, Input, Output, State\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StarMeter\") \\\n",
    "    .config(\"spark.jars\", \"jars/mysql-connector-java-8.4.0.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Function to retrieve fan counts with error handling\n",
    "def get_fan_counts():\n",
    "    try:\n",
    "        # Fetch data using Spark\n",
    "        df = spark.read.format(\"jdbc\") \\\n",
    "            .option(\"url\", \"jdbc:mysql://127.0.0.1:3306/starmeter\") \\\n",
    "            .option(\"dbtable\", \"user_dynamic_preferences\") \\\n",
    "            .option(\"user\", \"timlinkous\") \\\n",
    "            .option(\"password\", \"zipcode1\") \\\n",
    "            .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "            .load()\n",
    "\n",
    "        # Perform the aggregation using Spark\n",
    "        fan_counts_df = df.groupBy(\"current_favorite\").count().withColumnRenamed(\"count\", \"fan_count\")\n",
    "\n",
    "        # Convert to Pandas DataFrame for Dash processing\n",
    "        fan_counts_pd = fan_counts_df.toPandas()\n",
    "\n",
    "        if fan_counts_pd.empty:\n",
    "            print(\"Warning: The retrieved DataFrame is empty.\")\n",
    "        return fan_counts_pd\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "        return pd.DataFrame(columns=['current_favorite', 'fan_count'])\n",
    "\n",
    "\n",
    "\n",
    "def fetch_and_calculate_changes():\n",
    "    # Fetch data from MySQL\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/starmeter\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .option(\"dbtable\", \"event_log\") \\\n",
    "        .option(\"user\", \"timlinkous\") \\\n",
    "        .option(\"password\", \"zipcode1\") \\\n",
    "        .load()\n",
    "\n",
    "    # Convert to Pandas DataFrame and select necessary columns\n",
    "    pdf = df.select(\"event_date\", \"celebrity\", \"event_description\", \"current_fan_count\") \\\n",
    "        .orderBy(F.desc(\"event_date\")) \\\n",
    "        .limit(11).toPandas()\n",
    "    \n",
    "    # Sort by date in descending order\n",
    "    pdf = pdf.sort_values('event_date', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate fan_count_change\n",
    "    pdf['fan_count_change'] = pdf['current_fan_count'].diff(-1).fillna(0).astype(int)\n",
    "    \n",
    "    # Calculate percent change\n",
    "    pdf['percent_change'] = (pdf['fan_count_change'] / pdf['current_fan_count'].shift(-1)) * 100\n",
    "    \n",
    "    # Detect anomalies (changes >= 15%)\n",
    "    pdf['is_anomaly'] = np.abs(pdf['percent_change']) >= 15\n",
    "    \n",
    "    # Remove the extra row we used for calculation\n",
    "    pdf = pdf.iloc[:-1]\n",
    "\n",
    "    # Create the event log HTML using Dash components with specified font sizes\n",
    "    event_log_html = html.Div([\n",
    "        html.H4(\"Event Log\", style={'fontSize': '20px', 'marginBottom': '10px'}),\n",
    "        html.Table([\n",
    "            html.Thead(html.Tr([\n",
    "                html.Th(\"Date\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Celebrity\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Event\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Change\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"% Change\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Anomaly\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'})\n",
    "            ])),\n",
    "            html.Tbody([\n",
    "                html.Tr([\n",
    "                    html.Td(row['event_date'].strftime('%Y-%m-%d'), style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(row['celebrity'], style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(row['event_description'], style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(f\"{row['fan_count_change']:+d}\", style={'fontSize': '12px', 'padding': '5px', 'color': 'green' if row['fan_count_change'] > 0 else 'red' if row['fan_count_change'] < 0 else 'black'}),\n",
    "                    html.Td(f\"{row['percent_change']:.2f}%\" if not pd.isna(row['percent_change']) else \"N/A\", style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(\"ALERT\" if row['is_anomaly'] else \"\", style={'fontSize': '12px', 'padding': '5px', 'color': 'red', 'fontWeight': 'bold'})\n",
    "                ]) for _, row in pdf.iterrows()\n",
    "            ])\n",
    "        ], style={'width': '100%', 'textAlign': 'left', 'borderCollapse': 'collapse'})\n",
    "    ])\n",
    "    \n",
    "    return event_log_html\n",
    "\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Define custom styles for KPI cards\n",
    "card_styles = [\n",
    "    {\"backgroundColor\": \"#0075A4\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#008FAD\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#00A697\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#1EB769\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"}\n",
    "]\n",
    "\n",
    "# Initialize layout with KPI cards next to each other and graph with legend on top\n",
    "app.layout = html.Div([\n",
    "     dbc.Row([\n",
    "        dbc.Col(html.Button('Start', id='start-stop-button', n_clicks=0, className=\"btn btn-primary\"), width=\"auto\"),\n",
    "        dbc.Col(html.H1(\"StarMeter\", style={\"fontSize\": \"24px\"}), width=True)\n",
    "    ], align='center', className=\"mb-4\"),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Total Fans (in thousands)\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='total-fans', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[0], className=\"mb-2\"), width=2),\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Most Popular Celebrity\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='most-popular-celebrity', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[1], className=\"mb-2\"), width=2),\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Average Fans\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='average-fans', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[2], className=\"mb-2\"), width=2),\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Total Events\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='total-events', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[3], className=\"mb-2\"), width=2),\n",
    "    ], className=\"g-1\"),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='live-update-graph'), width=8),\n",
    "        dbc.Col(html.Div(id='event-log', children=\"Event log will be displayed here.\", style={\"height\": \"400px\", \"overflowY\": \"auto\", \"border\": \"1px solid #ddd\", \"padding\": \"10px\"}), width=4)\n",
    "    ]),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='bar-chart'), width=12)\n",
    "    ]),\n",
    "    \n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=1000,  # update interval milliseconds\n",
    "        n_intervals=0,\n",
    "        disabled=True  # interval initially disabled\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Initialize data storage\n",
    "fan_counts_data = {celebrity: [] for celebrity in ['Sabrina Carpenter', 'Snoop Dogg', 'Tony Stark', 'LeBron James']}\n",
    "time_data = []\n",
    "\n",
    "@app.callback(\n",
    "    [Output('live-update-graph', 'figure'),\n",
    "     Output('bar-chart', 'figure'),\n",
    "     Output('total-fans', 'children'),\n",
    "     Output('most-popular-celebrity', 'children'),\n",
    "     Output('average-fans', 'children'),\n",
    "     Output('total-events', 'children'),\n",
    "     Output('event-log', 'children')],  # Add this output for the event log\n",
    "    Input('interval-component', 'n_intervals')\n",
    ")\n",
    "def update_graph_and_kpis(n):\n",
    "    global time_data, fan_counts_data\n",
    "\n",
    "    try:\n",
    "        # Fetch latest fan counts and event log using Spark\n",
    "        fan_counts_df = get_fan_counts()  # Fetch fan counts\n",
    "        event_log_html = fetch_and_calculate_changes()  # Fetch event log data\n",
    "\n",
    "        # Initialize KPI variables\n",
    "        total_fans = 0\n",
    "        most_popular_celeb = None\n",
    "        max_fans = 0\n",
    "        total_events = 0\n",
    "        current_fan_counts = []  # To store the latest fan counts for the bar chart\n",
    "        colors = ['#0075A4', '#008FAD', '#00A697', '#1EB769']\n",
    "\n",
    "        if not fan_counts_df.empty:\n",
    "            # Append current timestamp\n",
    "            current_time = time.time()\n",
    "            time_data.append(current_time - time_data[0] if time_data else 0)\n",
    "\n",
    "            # Update fan counts data\n",
    "            for idx, celebrity in enumerate(fan_counts_data.keys()):\n",
    "                # Fetch the latest fan count for each celebrity\n",
    "                fan_count = fan_counts_df[fan_counts_df['current_favorite'] == celebrity]['fan_count'].sum() if not fan_counts_df[fan_counts_df['current_favorite'] == celebrity].empty else 0\n",
    "                fan_counts_data[celebrity].append(fan_count)\n",
    "                current_fan_counts.append(fan_count)  # Add to current fan counts for bar chart\n",
    "                total_events += len(fan_counts_data[celebrity])\n",
    "\n",
    "                # Update total fans and most popular celebrity\n",
    "                total_fans += fan_count\n",
    "                if fan_count > max_fans:\n",
    "                    max_fans = fan_count\n",
    "                    most_popular_celeb = celebrity\n",
    "\n",
    "            colors = [\n",
    "                '#1f77b4',  # muted blue\n",
    "                '#9467bd',  # muted purple\n",
    "                '#d62728',  # brick red\n",
    "                '#17becf'   # blue-teal\n",
    "            ]\n",
    "            \n",
    "            # Create traces for each celebrity in the line chart\n",
    "            line_fig = go.Figure()\n",
    "            for idx, (celebrity, fan_counts) in enumerate(fan_counts_data.items()):\n",
    "                line_fig.add_trace(go.Scatter(\n",
    "                    x=time_data,\n",
    "                    y=fan_counts,\n",
    "                    mode='lines+markers',\n",
    "                    name=celebrity,\n",
    "                    marker=dict(size=5, color=colors[idx]),\n",
    "                    line=dict(color=colors[idx]),\n",
    "                    text=['Event happened here'] * len(fan_counts),\n",
    "                    hoverinfo='text',\n",
    "                    customdata=list(range(len(fan_counts))),  # Index of the markers\n",
    "                ))\n",
    "\n",
    "            # Ensure time_data has enough data points to set range\n",
    "            if len(time_data) > 1:\n",
    "                line_fig.update_layout(\n",
    "                    xaxis=dict(range=[max(time_data) - 100, max(time_data)]),\n",
    "                )\n",
    "\n",
    "            line_fig.update_layout(\n",
    "                xaxis=dict(\n",
    "                    range=[max(0, max(time_data) - 100), max(time_data)],\n",
    "                    fixedrange=True,  # Prevents zooming/panning from affecting range\n",
    "                    showticklabels=False,  # Hides x-axis labels\n",
    "                ),\n",
    "                xaxis_title='Time (Days)',\n",
    "                yaxis_title='Number of Fans (in thousands)',\n",
    "                margin=dict(l=0, r=0, t=40, b=0),  # Adjust margins to fit the layout\n",
    "                autosize=False,  # Disable autosize to fix width\n",
    "                width=900,  # Set the desired width\n",
    "                height=400,  # Set the desired height\n",
    "                showlegend=True,\n",
    "                legend=dict(\n",
    "                    orientation='h',  # Horizontal orientation\n",
    "                    yanchor='bottom',\n",
    "                    y=1.15,\n",
    "                    xanchor='right',\n",
    "                    x=1\n",
    "                ),\n",
    "                modebar=dict(\n",
    "                    remove=['zoom', 'pan', 'select', 'zoomIn', 'zoomOut', 'autoScale', 'resetScale2d', 'lasso2d', 'zoom2d', 'resetScale', 'toImage', 'plotly_logo']\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "            # Create bar chart for current fan counts\n",
    "            bar_fig = go.Figure(data=[\n",
    "                go.Bar(\n",
    "                    x=list(fan_counts_data.keys()),\n",
    "                    y=current_fan_counts,  # Use the latest counts\n",
    "                    marker_color=colors,  # Match colors with the line graph\n",
    "                    width=0.4  # Set the bar width; adjust as needed\n",
    "                )\n",
    "            ])\n",
    "            # Set the y-axis range to the total current fans\n",
    "            bar_fig.update_layout(\n",
    "                title='Current Fans per Celebrity',\n",
    "                xaxis_title='Celebrity',\n",
    "                yaxis_title='Current Fans',\n",
    "                yaxis=dict(range=[0, (total_fans/2)-1000]),  # Set range based on total fans\n",
    "                margin=dict(l=40, r=40, t=40, b=80),  # Adjust margins to fit the layout\n",
    "                autosize=True,\n",
    "                width=400,  # Set the desired width\n",
    "                height=400,  # Set the desired height\n",
    "                showlegend=False,\n",
    "                modebar=dict(\n",
    "                    remove=['zoom', 'pan', 'select', 'zoomIn', 'zoomOut', 'autoScale', 'resetScale2d', 'lasso2d', 'zoom2d', 'resetScale', 'toImage', 'plotly_logo']\n",
    "                )\n",
    "            )\n",
    "            bar_fig.update_xaxes(tickangle=-45)  # Rotate x-axis labels if needed\n",
    "\n",
    "        else:\n",
    "            line_fig = go.Figure().update_layout(\n",
    "                title='No data available',\n",
    "                xaxis_title='Time (seconds)',\n",
    "                yaxis_title='Number of Fans'\n",
    "            )\n",
    "            bar_fig = go.Figure().update_layout(\n",
    "                title='No data available',\n",
    "                xaxis_title='Celebrity',\n",
    "                yaxis_title='Current Fans'\n",
    "            )\n",
    "\n",
    "        average_fans = total_fans // len(fan_counts_data) if fan_counts_data else 0\n",
    "\n",
    "        return line_fig, bar_fig, f'{total_fans}', most_popular_celeb or 'No data', f'{average_fans}', f'{total_events}', event_log_html\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in updating graph and KPIs: {e}\")\n",
    "        return go.Figure().update_layout(title=\"Error updating graph\"), go.Figure().update_layout(title=\"Error updating graph\"), 'Error', 'Error', 'Error', 'Error', html.Div([\"Error updating event log\"])\n",
    "\n",
    "\n",
    "# Callback control start stop functionality\n",
    "@app.callback(\n",
    "    [Output('interval-component', 'disabled'),\n",
    "     Output('start-stop-button', 'children')],\n",
    "    [Input('start-stop-button', 'n_clicks')],\n",
    "    [State('interval-component', 'disabled')]\n",
    ")\n",
    "\n",
    "def toggle_interval(n_clicks, is_disabled):\n",
    "    # Toggle state interval (start stop updates)\n",
    "    if n_clicks % 2 == 0:\n",
    "        return True, 'Start'  # disabled, show 'Start' button text\n",
    "    else:\n",
    "        return False, 'Stop'  # enabled, show 'Stop' button text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: sentence-transformers in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: pinecone-client in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (5.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (0.24.6)\n",
      "Requirement already satisfied: Pillow in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (2024.2.2)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (1.0.3)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (2.2.1)\n",
      "Requirement already satisfied: filelock in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: sympy in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (70.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy sentence-transformers pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (2024.2.2)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (1.0.3)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pinecone-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed: collected_text_4.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=\"00fdf680-fdf4-458a-9d14-5271f9ab7002\")\n",
    "\n",
    "index_name = \"event-similarity\"\n",
    "\n",
    "# Check if the index exists, if not create it\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def truncate_content(content, max_bytes=40000):\n",
    "    \"\"\"Truncate content to fit within Pinecone's metadata size limit.\"\"\"\n",
    "    encoded_content = content.encode('utf-8')\n",
    "    if len(encoded_content) <= max_bytes:\n",
    "        return content\n",
    "    return encoded_content[:max_bytes].decode('utf-8', 'ignore')\n",
    "\n",
    "def process_and_index_articles(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r') as file:\n",
    "                content = file.read()\n",
    "                \n",
    "                # Create embedding\n",
    "                embedding = model.encode(content)\n",
    "                \n",
    "                # Truncate content to fit within metadata size limit\n",
    "                truncated_content = truncate_content(content)\n",
    "                \n",
    "                # Index the document\n",
    "                try:\n",
    "                    index.upsert(vectors=[(filename, embedding.tolist(), {\"content\": truncated_content})])\n",
    "                    print(f\"Indexed: {filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error indexing {filename}: {str(e)}\")\n",
    "                    # You might want to log this error or handle it in some way\n",
    "\n",
    "# Usage\n",
    "article_directory = \"/Users/timl/Projects/txt files/Sabrina Carpenter\"\n",
    "process_and_index_articles(article_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event 8825, Description: 'Public argument/feud...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1075\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0573\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0264\n",
      "\n",
      "Event 8826, Description: 'Talk show appearance...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.3735\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0219\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0058\n",
      "\n",
      "Event 8828, Description: 'Releases new shoe/product...' matches articles:\n",
      "  - ID: june_28.txt, Description: None, Score: 0.1358\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0886\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0351\n",
      "\n",
      "Event 8829, Description: 'Editorial Article...' matches articles:\n",
      "  - ID: june_28.txt, Description: None, Score: 0.1310\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0594\n",
      "  - ID: collected_text_4.txt, Description: None, Score: -0.0365\n",
      "\n",
      "Event 8831, Description: 'Cameo appearance...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.2930\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0905\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0104\n",
      "\n",
      "Event 8832, Description: 'Book/memoir released...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0142\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0048\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0746\n",
      "\n",
      "Event 8835, Description: 'Philanthropy/donation...' matches articles:\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0447\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0024\n",
      "  - ID: collected_text_4.txt, Description: None, Score: -0.0266\n",
      "\n",
      "Event 8838, Description: 'New social media platform...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1195\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0682\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0091\n",
      "\n",
      "Event 8839, Description: 'New project and franchise...' matches articles:\n",
      "  - ID: june_28.txt, Description: None, Score: 0.1369\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0617\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0544\n",
      "\n",
      "Event 8842, Description: 'Social media post (pos)...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0939\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0360\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0307\n",
      "\n",
      "Event 8843, Description: 'Attends high profile event...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.2173\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0915\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0676\n",
      "\n",
      "Event 8844, Description: 'Poor performance...' matches articles:\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.1648\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0902\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0381\n",
      "\n",
      "Event 8850, Description: 'Celebrity collaboration...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.2547\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0700\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0463\n",
      "\n",
      "Event 8851, Description: 'Health & fitness photo...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0502\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0289\n",
      "  - ID: june_28.txt, Description: None, Score: -0.0010\n",
      "\n",
      "Event 8855, Description: 'Public appearance...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1916\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0299\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0289\n",
      "\n",
      "Event 8856, Description: 'Social media post (neg)...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1004\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0410\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0301\n",
      "\n",
      "Event 8859, Description: 'Controversial statement...' matches articles:\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0636\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0136\n",
      "  - ID: june_28.txt, Description: None, Score: -0.0284\n",
      "\n",
      "Event 8864, Description: 'Scandalous clothing...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1551\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0155\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0319\n",
      "\n",
      "Event 8865, Description: 'New Feature film...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1316\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0547\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0470\n",
      "\n",
      "Event 8873, Description: 'Health declines...' matches articles:\n",
      "  - ID: june_28.txt, Description: None, Score: 0.1492\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0100\n",
      "  - ID: collected_text_4.txt, Description: None, Score: -0.0033\n",
      "\n",
      "Event 8886, Description: 'Major news story...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0765\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0536\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0371\n",
      "\n",
      "Event 8888, Description: 'Wins Award...' matches articles:\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.2198\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0303\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0113\n",
      "\n",
      "Event 8896, Description: 'Podcast appearance...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.3226\n",
      "  - ID: june_28.txt, Description: None, Score: 0.1070\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0981\n",
      "\n",
      "Event 8905, Description: 'Bizarre fashion choice...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1403\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0821\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0023\n",
      "\n",
      "Event 8906, Description: 'Political statements...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0139\n",
      "  - ID: june_28.txt, Description: None, Score: -0.0589\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0740\n",
      "\n",
      "Event 8909, Description: 'Reacts to fan requests...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0393\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0069\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0146\n",
      "\n",
      "Event 8910, Description: 'Legal issues...' matches articles:\n",
      "  - ID: june_28.txt, Description: None, Score: 0.1069\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0599\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0819\n",
      "\n",
      "Event 8917, Description: 'Gets married...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.0200\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0167\n",
      "  - ID: june_28.txt, Description: None, Score: -0.0362\n",
      "\n",
      "Event 8923, Description: 'Candid public photos...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1408\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0166\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0043\n",
      "\n",
      "Event 8929, Description: 'Releases new album/tour...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1380\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0771\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0156\n",
      "\n",
      "Event 9043, Description: 'Teaser released...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.2082\n",
      "  - ID: june_28.txt, Description: None, Score: 0.1087\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0489\n",
      "\n",
      "Event 9079, Description: 'Wears new Iron Man suit...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.1564\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0872\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0401\n",
      "\n",
      "Event 9130, Description: 'Featured in a new song...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.2455\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0197\n",
      "  - ID: aug_10.txt, Description: None, Score: -0.0089\n",
      "\n",
      "Event 9201, Description: 'Hosts SNL...' matches articles:\n",
      "  - ID: collected_text_4.txt, Description: None, Score: 0.4880\n",
      "  - ID: june_28.txt, Description: None, Score: 0.0863\n",
      "  - ID: aug_10.txt, Description: None, Score: 0.0495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=\"00fdf680-fdf4-458a-9d14-5271f9ab7002\")\n",
    "index = pc.Index(\"event-similarity\")\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Retrieve event descriptions from MySQL and deduplicate\n",
    "def get_unique_event_descriptions():\n",
    "    db = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"timlinkous\",\n",
    "        password=\"zipcode1\",\n",
    "        database=\"starmeter\"\n",
    "    )\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(\"SELECT event_id, event_description FROM event_log\")\n",
    "    events = cursor.fetchall()\n",
    "    \n",
    "    # Deduplicate events based on description\n",
    "    unique_events = defaultdict(list)\n",
    "    for event_id, description in events:\n",
    "        unique_events[description].append(event_id)\n",
    "    \n",
    "    return [(ids[0], desc) for desc, ids in unique_events.items()]\n",
    "\n",
    "def find_similar_articles():\n",
    "    unique_events = get_unique_event_descriptions()\n",
    "    similar_articles = {}\n",
    "    \n",
    "    for event_id, description in unique_events:\n",
    "        event_vector = model.encode(description).tolist()\n",
    "        # Perform similarity search in Pinecone\n",
    "        results = index.query(vector=event_vector, top_k=10, include_metadata=True)\n",
    "        \n",
    "        # Sort matches by score in descending order and remove duplicates\n",
    "        seen_ids = set()\n",
    "        sorted_unique_matches = []\n",
    "        for match in sorted(results.matches, key=lambda x: x.score, reverse=True):\n",
    "            if match.id not in seen_ids:\n",
    "                sorted_unique_matches.append(match)\n",
    "                seen_ids.add(match.id)\n",
    "            if len(sorted_unique_matches) == 5:  # Limit to top 5 unique matches\n",
    "                break\n",
    "        \n",
    "        similar_articles[event_id] = sorted_unique_matches\n",
    "        print(f\"Event {event_id}, Description: '{description[:50]}...' matches articles:\")\n",
    "        for match in sorted_unique_matches:\n",
    "            print(f\"  - ID: {match.id}, Description: {match.description}, Score: {match.score:.4f}\")\n",
    "        print()  # Add a blank line for readability\n",
    "    \n",
    "    return similar_articles\n",
    "\n",
    "# Usage\n",
    "event_article_matches = find_similar_articles()\n",
    "\n",
    "# You can now use event_article_matches in your application\n",
    "# It's a dictionary where keys are event_ids and values are lists of unique similar articles sorted by score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
