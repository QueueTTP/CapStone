{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x131353080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import dash\n",
    "from pyspark.sql.functions import desc\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "from dash import dcc, html, Output, Input, State\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from dash import dcc, html, Input, Output, State\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StarMeter\") \\\n",
    "    .config(\"spark.jars\", \"jars/mysql-connector-java-8.4.0.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Function to retrieve fan counts with error handling\n",
    "def get_fan_counts():\n",
    "    try:\n",
    "        # Fetch data using Spark\n",
    "        df = spark.read.format(\"jdbc\") \\\n",
    "            .option(\"url\", \"jdbc:mysql://127.0.0.1:3306/starmeter\") \\\n",
    "            .option(\"dbtable\", \"user_dynamic_preferences\") \\\n",
    "            .option(\"user\", \"timlinkous\") \\\n",
    "            .option(\"password\", \"zipcode1\") \\\n",
    "            .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "            .load()\n",
    "\n",
    "        # Perform the aggregation using Spark\n",
    "        fan_counts_df = df.groupBy(\"current_favorite\").count().withColumnRenamed(\"count\", \"fan_count\")\n",
    "\n",
    "        # Convert to Pandas DataFrame for Dash processing\n",
    "        fan_counts_pd = fan_counts_df.toPandas()\n",
    "\n",
    "        if fan_counts_pd.empty:\n",
    "            print(\"Warning: The retrieved DataFrame is empty.\")\n",
    "        return fan_counts_pd\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "        return pd.DataFrame(columns=['current_favorite', 'fan_count'])\n",
    "\n",
    "\n",
    "\n",
    "def fetch_and_calculate_changes():\n",
    "    # Fetch data from MySQL\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/starmeter\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .option(\"dbtable\", \"event_log\") \\\n",
    "        .option(\"user\", \"timlinkous\") \\\n",
    "        .option(\"password\", \"zipcode1\") \\\n",
    "        .load()\n",
    "\n",
    "    # Convert to Pandas DataFrame and select necessary columns\n",
    "    pdf = df.select(\"event_date\", \"celebrity\", \"event_description\", \"current_fan_count\") \\\n",
    "        .orderBy(F.desc(\"event_date\")) \\\n",
    "        .limit(11).toPandas()\n",
    "    \n",
    "    # Sort by date in descending order\n",
    "    pdf = pdf.sort_values('event_date', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate fan_count_change\n",
    "    pdf['fan_count_change'] = pdf['current_fan_count'].diff(-1).fillna(0).astype(int)\n",
    "    \n",
    "    # Calculate percent change\n",
    "    pdf['percent_change'] = (pdf['fan_count_change'] / pdf['current_fan_count'].shift(-1)) * 100\n",
    "    \n",
    "    # Detect anomalies (changes >= 15%)\n",
    "    pdf['is_anomaly'] = np.abs(pdf['percent_change']) >= 15\n",
    "    \n",
    "    # Remove the extra row we used for calculation\n",
    "    pdf = pdf.iloc[:-1]\n",
    "\n",
    "    # Create the event log HTML using Dash components with specified font sizes\n",
    "    event_log_html = html.Div([\n",
    "        html.H4(\"Event Log\", style={'fontSize': '20px', 'marginBottom': '10px'}),\n",
    "        html.Table([\n",
    "            html.Thead(html.Tr([\n",
    "                html.Th(\"Date\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Celebrity\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Event\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Change\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"% Change\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'}),\n",
    "                html.Th(\"Anomaly\", style={'fontSize': '12px', 'fontWeight': 'bold', 'padding': '5px'})\n",
    "            ])),\n",
    "            html.Tbody([\n",
    "                html.Tr([\n",
    "                    html.Td(row['event_date'].strftime('%Y-%m-%d'), style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(row['celebrity'], style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(row['event_description'], style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(f\"{row['fan_count_change']:+d}\", style={'fontSize': '12px', 'padding': '5px', 'color': 'green' if row['fan_count_change'] > 0 else 'red' if row['fan_count_change'] < 0 else 'black'}),\n",
    "                    html.Td(f\"{row['percent_change']:.2f}%\" if not pd.isna(row['percent_change']) else \"N/A\", style={'fontSize': '12px', 'padding': '5px'}),\n",
    "                    html.Td(\"ALERT\" if row['is_anomaly'] else \"\", style={'fontSize': '12px', 'padding': '5px', 'color': 'red', 'fontWeight': 'bold'})\n",
    "                ]) for _, row in pdf.iterrows()\n",
    "            ])\n",
    "        ], style={'width': '100%', 'textAlign': 'left', 'borderCollapse': 'collapse'})\n",
    "    ])\n",
    "    \n",
    "    return event_log_html\n",
    "\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Define custom styles for KPI cards\n",
    "card_styles = [\n",
    "    {\"backgroundColor\": \"#0075A4\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#008FAD\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#00A697\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"},\n",
    "    {\"backgroundColor\": \"#1EB769\", \"color\": \"white\", \"padding\": \"0px\", \"borderRadius\": \"10px\", \"width\": \"200px\", \"height\": \"60px\", \"lineHeight\": \"1\"}\n",
    "]\n",
    "\n",
    "# Initialize layout with KPI cards next to each other and graph with legend on top\n",
    "app.layout = html.Div([\n",
    "     dbc.Row([\n",
    "        dbc.Col(html.Button('Start', id='start-stop-button', n_clicks=0, className=\"btn btn-primary\"), width=\"auto\"),\n",
    "        dbc.Col(html.H1(\"StarMeter\", style={\"fontSize\": \"24px\"}), width=True)\n",
    "    ], align='center', className=\"mb-4\"),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Total Fans (in thousands)\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='total-fans', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[0], className=\"mb-2\"), width=2),\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Most Popular Celebrity\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='most-popular-celebrity', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[1], className=\"mb-2\"), width=2),\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Average Fans\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='average-fans', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[2], className=\"mb-2\"), width=2),\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Total Events\", className=\"card-title\", style={\"fontSize\": \"12px\", \"margin\": \"0\"}),\n",
    "                html.H5(id='total-events', className=\"card-text\", style={\"fontSize\": \"16px\", \"margin\": \"0\"})\n",
    "            ])\n",
    "        ], style=card_styles[3], className=\"mb-2\"), width=2),\n",
    "    ], className=\"g-1\"),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='live-update-graph'), width=8),\n",
    "        dbc.Col(html.Div(id='event-log', children=\"Event log will be displayed here.\", style={\"height\": \"400px\", \"overflowY\": \"auto\", \"border\": \"1px solid #ddd\", \"padding\": \"10px\"}), width=4)\n",
    "    ]),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='bar-chart'), width=12)\n",
    "    ]),\n",
    "    \n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=1000,  # update interval milliseconds\n",
    "        n_intervals=0,\n",
    "        disabled=True  # interval initially disabled\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Initialize data storage\n",
    "fan_counts_data = {celebrity: [] for celebrity in ['Sabrina Carpenter', 'Snoop Dogg', 'Tony Stark', 'LeBron James']}\n",
    "time_data = []\n",
    "\n",
    "@app.callback(\n",
    "    [Output('live-update-graph', 'figure'),\n",
    "     Output('bar-chart', 'figure'),\n",
    "     Output('total-fans', 'children'),\n",
    "     Output('most-popular-celebrity', 'children'),\n",
    "     Output('average-fans', 'children'),\n",
    "     Output('total-events', 'children'),\n",
    "     Output('event-log', 'children')],  # Add this output for the event log\n",
    "    Input('interval-component', 'n_intervals')\n",
    ")\n",
    "def update_graph_and_kpis(n):\n",
    "    global time_data, fan_counts_data\n",
    "\n",
    "    try:\n",
    "        # Fetch latest fan counts and event log using Spark\n",
    "        fan_counts_df = get_fan_counts()  # Fetch fan counts\n",
    "        event_log_html = fetch_and_calculate_changes()  # Fetch event log data\n",
    "\n",
    "        # Initialize KPI variables\n",
    "        total_fans = 0\n",
    "        most_popular_celeb = None\n",
    "        max_fans = 0\n",
    "        total_events = 0\n",
    "        current_fan_counts = []  # To store the latest fan counts for the bar chart\n",
    "        colors = ['#0075A4', '#008FAD', '#00A697', '#1EB769']\n",
    "\n",
    "        if not fan_counts_df.empty:\n",
    "            # Append current timestamp\n",
    "            current_time = time.time()\n",
    "            time_data.append(current_time - time_data[0] if time_data else 0)\n",
    "\n",
    "            # Update fan counts data\n",
    "            for idx, celebrity in enumerate(fan_counts_data.keys()):\n",
    "                # Fetch the latest fan count for each celebrity\n",
    "                fan_count = fan_counts_df[fan_counts_df['current_favorite'] == celebrity]['fan_count'].sum() if not fan_counts_df[fan_counts_df['current_favorite'] == celebrity].empty else 0\n",
    "                fan_counts_data[celebrity].append(fan_count)\n",
    "                current_fan_counts.append(fan_count)  # Add to current fan counts for bar chart\n",
    "                total_events += len(fan_counts_data[celebrity])\n",
    "\n",
    "                # Update total fans and most popular celebrity\n",
    "                total_fans += fan_count\n",
    "                if fan_count > max_fans:\n",
    "                    max_fans = fan_count\n",
    "                    most_popular_celeb = celebrity\n",
    "\n",
    "            colors = [\n",
    "                '#1f77b4',  # muted blue\n",
    "                '#9467bd',  # muted purple\n",
    "                '#d62728',  # brick red\n",
    "                '#17becf'   # blue-teal\n",
    "            ]\n",
    "            \n",
    "            # Create traces for each celebrity in the line chart\n",
    "            line_fig = go.Figure()\n",
    "            for idx, (celebrity, fan_counts) in enumerate(fan_counts_data.items()):\n",
    "                line_fig.add_trace(go.Scatter(\n",
    "                    x=time_data,\n",
    "                    y=fan_counts,\n",
    "                    mode='lines+markers',\n",
    "                    name=celebrity,\n",
    "                    marker=dict(size=5, color=colors[idx]),\n",
    "                    line=dict(color=colors[idx]),\n",
    "                    text=['Event happened here'] * len(fan_counts),\n",
    "                    hoverinfo='text',\n",
    "                    customdata=list(range(len(fan_counts))),  # Index of the markers\n",
    "                ))\n",
    "\n",
    "            # Ensure time_data has enough data points to set range\n",
    "            if len(time_data) > 1:\n",
    "                line_fig.update_layout(\n",
    "                    xaxis=dict(range=[max(time_data) - 100, max(time_data)]),\n",
    "                )\n",
    "\n",
    "            line_fig.update_layout(\n",
    "                xaxis=dict(\n",
    "                    range=[max(0, max(time_data) - 100), max(time_data)],\n",
    "                    fixedrange=True,  # Prevents zooming/panning from affecting range\n",
    "                    showticklabels=False,  # Hides x-axis labels\n",
    "                ),\n",
    "                xaxis_title='Time (Days)',\n",
    "                yaxis_title='Number of Fans (in thousands)',\n",
    "                margin=dict(l=0, r=0, t=40, b=0),  # Adjust margins to fit the layout\n",
    "                autosize=False,  # Disable autosize to fix width\n",
    "                width=900,  # Set the desired width\n",
    "                height=400,  # Set the desired height\n",
    "                showlegend=True,\n",
    "                legend=dict(\n",
    "                    orientation='h',  # Horizontal orientation\n",
    "                    yanchor='bottom',\n",
    "                    y=1.15,\n",
    "                    xanchor='right',\n",
    "                    x=1\n",
    "                ),\n",
    "                modebar=dict(\n",
    "                    remove=['zoom', 'pan', 'select', 'zoomIn', 'zoomOut', 'autoScale', 'resetScale2d', 'lasso2d', 'zoom2d', 'resetScale', 'toImage', 'plotly_logo']\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "            # Create bar chart for current fan counts\n",
    "            bar_fig = go.Figure(data=[\n",
    "                go.Bar(\n",
    "                    x=list(fan_counts_data.keys()),\n",
    "                    y=current_fan_counts,  # Use the latest counts\n",
    "                    marker_color=colors,  # Match colors with the line graph\n",
    "                    width=0.4  # Set the bar width; adjust as needed\n",
    "                )\n",
    "            ])\n",
    "            # Set the y-axis range to the total current fans\n",
    "            bar_fig.update_layout(\n",
    "                title='Current Fans per Celebrity',\n",
    "                xaxis_title='Celebrity',\n",
    "                yaxis_title='Current Fans',\n",
    "                yaxis=dict(range=[0, (total_fans/2)-1000]),  # Set range based on total fans\n",
    "                margin=dict(l=40, r=40, t=40, b=80),  # Adjust margins to fit the layout\n",
    "                autosize=True,\n",
    "                width=400,  # Set the desired width\n",
    "                height=400,  # Set the desired height\n",
    "                showlegend=False,\n",
    "                modebar=dict(\n",
    "                    remove=['zoom', 'pan', 'select', 'zoomIn', 'zoomOut', 'autoScale', 'resetScale2d', 'lasso2d', 'zoom2d', 'resetScale', 'toImage', 'plotly_logo']\n",
    "                )\n",
    "            )\n",
    "            bar_fig.update_xaxes(tickangle=-45)  # Rotate x-axis labels if needed\n",
    "\n",
    "        else:\n",
    "            line_fig = go.Figure().update_layout(\n",
    "                title='No data available',\n",
    "                xaxis_title='Time (seconds)',\n",
    "                yaxis_title='Number of Fans'\n",
    "            )\n",
    "            bar_fig = go.Figure().update_layout(\n",
    "                title='No data available',\n",
    "                xaxis_title='Celebrity',\n",
    "                yaxis_title='Current Fans'\n",
    "            )\n",
    "\n",
    "        average_fans = total_fans // len(fan_counts_data) if fan_counts_data else 0\n",
    "\n",
    "        return line_fig, bar_fig, f'{total_fans}', most_popular_celeb or 'No data', f'{average_fans}', f'{total_events}', event_log_html\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in updating graph and KPIs: {e}\")\n",
    "        return go.Figure().update_layout(title=\"Error updating graph\"), go.Figure().update_layout(title=\"Error updating graph\"), 'Error', 'Error', 'Error', 'Error', html.Div([\"Error updating event log\"])\n",
    "\n",
    "\n",
    "# Callback control start stop functionality\n",
    "@app.callback(\n",
    "    [Output('interval-component', 'disabled'),\n",
    "     Output('start-stop-button', 'children')],\n",
    "    [Input('start-stop-button', 'n_clicks')],\n",
    "    [State('interval-component', 'disabled')]\n",
    ")\n",
    "\n",
    "def toggle_interval(n_clicks, is_disabled):\n",
    "    # Toggle state interval (start stop updates)\n",
    "    if n_clicks % 2 == 0:\n",
    "        return True, 'Start'  # disabled, show 'Start' button text\n",
    "    else:\n",
    "        return False, 'Stop'  # enabled, show 'Stop' button text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (1.26.4)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (2024.2.2)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Using cached pinecone_plugin_inference-1.0.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pinecone-client) (2.2.1)\n",
      "Collecting filelock (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading filelock-3.16.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.2)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (70.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Using cached pinecone_plugin_inference-1.0.3-py3-none-any.whl (117 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.8/381.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Downloading filelock-3.16.0-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, pinecone-plugin-interface, networkx, fsspec, filelock, torch, pinecone-plugin-inference, huggingface-hub, tokenizers, pinecone-client, transformers, sentence-transformers\n",
      "Successfully installed filelock-3.16.0 fsspec-2024.9.0 huggingface-hub-0.24.6 mpmath-1.3.0 networkx-3.3 pinecone-client-5.0.1 pinecone-plugin-inference-1.0.3 pinecone-plugin-interface-0.0.7 safetensors-0.4.5 sentence-transformers-3.0.1 sympy-1.13.2 tokenizers-0.19.1 torch-2.4.1 transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy sentence-transformers pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6830a47793470eb2a7fc5ffe58f7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9620cfe21091405ca37a23b731148f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87594d69849a4dc89b60a0e6725c3136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a38636bd144dce98809b4d038575b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646a0333067c4f18ad9502d09b8d28fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa21aa14fdba40fcb00a222cfa112ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bff952db3c4a9fb88cfe0ed2b4685f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f238873c0ac436a9530133f728018ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e637e60ec6864f1cb40d5c3f24f79dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6455a87622a247d7a1df5e03900b93ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timl/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8027867b09454f10a5d824f730addf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "def extract_event_log():\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            database='starmeter',\n",
    "            user='timlinkous',\n",
    "            password='zipcode1'\n",
    "        )\n",
    "\n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor(dictionary=True)\n",
    "            query = \"SELECT * FROM event_log\"\n",
    "            cursor.execute(query)\n",
    "            event_log_data = cursor.fetchall()\n",
    "            return event_log_data\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error while connecting to MySQL: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "# Usage\n",
    "event_data = extract_event_log()\n",
    "\n",
    "\n",
    "def prepare_data_for_pinecone(event_data):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    prepared_data = []\n",
    "    for event in event_data:\n",
    "        # Combine relevant fields into a single text\n",
    "        text = f\"{event['celebrity']} {event['event_description']}\"\n",
    "        \n",
    "        # Generate embedding\n",
    "        embedding = model.encode(text)\n",
    "        \n",
    "        # Prepare the data structure for Pinecone\n",
    "        prepared_data.append({\n",
    "            'id': str(event['event_id']),\n",
    "            'values': embedding.tolist(),\n",
    "            'metadata': {\n",
    "                'date': event['event_date'].isoformat(),\n",
    "                'celebrity': event['celebrity'],\n",
    "                'description': event['event_description'],\n",
    "                'fan_count': event['current_fan_count']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "# Usage\n",
    "prepared_data = prepare_data_for_pinecone(event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pinecone' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prepared_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m events in Pinecone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mindex_data_in_pinecone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(query, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Initialize Pinecone (if not already initialized)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     pinecone\u001b[38;5;241m.\u001b[39minit(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m, environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_environment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mindex_data_in_pinecone\u001b[0;34m(prepared_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindex_data_in_pinecone\u001b[39m(prepared_data):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Initialize Pinecone\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m, environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_environment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Create or connect to an existing index\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcelebrity_events\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pinecone' has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "def index_data_in_pinecone(prepared_data):\n",
    "    # Initialize Pinecone\n",
    "    pinecone.init(api_key=\"00fdf680-fdf4-458a-9d14-5271f9ab7002\", environment=\"your_environment\")\n",
    "    \n",
    "    # Create or connect to an existing index\n",
    "    index_name = \"celebrity-events\"\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        pinecone.create_index(index_name, dimension=384)  # Dimension depends on your embedding model\n",
    "    \n",
    "    index = pinecone.Index(index_name)\n",
    "    \n",
    "    # Upsert data in batches\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(prepared_data), batch_size):\n",
    "        batch = prepared_data[i:i+batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "\n",
    "    print(f\"Indexed {len(prepared_data)} events in Pinecone\")\n",
    "\n",
    "# Usage\n",
    "index_data_in_pinecone(prepared_data)\n",
    "\n",
    "\n",
    "def similarity_search(query, top_k=5):\n",
    "    # Initialize Pinecone (if not already initialized)\n",
    "    pinecone.init(api_key=\"00fdf680-fdf4-458a-9d14-5271f9ab7002\", environment=\"your_environment\")\n",
    "    index = pinecone.Index(\"celebrity_events\")\n",
    "    \n",
    "    # Generate embedding for the query\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    query_embedding = model.encode(query).tolist()\n",
    "    \n",
    "    # Perform the search\n",
    "    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "query = \"Celebrity X scandal during award show\"\n",
    "similar_events = similarity_search(query)\n",
    "\n",
    "# Process and display results\n",
    "for match in similar_events['matches']:\n",
    "    print(f\"Event ID: {match['id']}\")\n",
    "    print(f\"Similarity Score: {match['score']}\")\n",
    "    print(f\"Date: {match['metadata']['date']}\")\n",
    "    print(f\"Celebrity: {match['metadata']['celebrity']}\")\n",
    "    print(f\"Description: {match['metadata']['description']}\")\n",
    "    print(f\"Fan Count: {match['metadata']['fan_count']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
